---
title: 操作系统-设计与实现-四
date: 2021-08-10 09:21:41
tags: ['手写','操作系统']
categories: ['手写']
---


# 前言

  jyy老师太强了。这一章介绍一下并发控制中互斥相关的内容，并实现课程中的L1实验

# 互斥

  实现共享内存上的互斥，并不是一个非常简单的事情:
  1. 系统不能**同时**读/写共享内存(除了原子指令)，即`load`时不能写，只能单纯的读;而写的时候，无法进行读(即使类似于`addq $1, [sum]`这种指令，其也是分为读值、计算和写值三部分)。从而当一个线程完成状态读取和状态设置时，其实这两者之间可能状态已经发生了变化(另一个线程完成了状态读取和状态设置)
  2. 系统可能**乱序**执行指令。可能有些精妙的算法可以规避1.中的问题，例如**Peterson算法**。但是现代操作系统可能的指令乱序执行(即可能在读之前完成写)，也会导致互斥的失败


  可以看到，单纯的从软件上实现共享内存的互斥是非常困难的一件事情，因此这就往往需要硬件上进行协调配合!
  硬件可以通过诸如锁总线的方式，原子的实现**load-exec-store**指令，从而为我们实现共享内存上的互斥提供了有效的解决方法。
  这些原子指令，完美的解决了上面的两个难点，因此很容易就实现共享内存的互斥。这些方案往往简洁，且很好理解，如下面基于**xchg**的自选锁实现的共享内存的互斥。

  ```c
int locked = 0;

void lock() {
	while(xchg(&locked, 1));
}

void unlock() {
	xchg(&locked, 0);
}
```

  可以看到，由于**xchg**是原子的，因此任何时候，永远只可能有一个线程，在执行**lock**或**unlock**中的**xchg**指令，而只要有线程成功获取了锁(**xchg**返回的值为0)，则其同时会将`locked`的值设置为1，直到其归还锁之前，不会再有其他人获取锁。因此其简洁的实现了共享内存的互斥


# L1物理内存管理(pmm)

## 实验背景

  从这次实验开始，我们将真正的开始实现一个操作系统。
  在实现操作系统内核时，经常会需要为操作系统中新增的对象分配存储空间。在这些对象不再使用时，有需要将这些对象的内存进行回收。例如在前面的**M2**中调用`co_start`分配协程结构体资源;调用`co_wait`回收上述分配的资源。
  当然，对于迷你自制的操作系统来说，每种类型的资源都进行手工分配和释放是完全可行的。但是实现内存的自动分配和释放，可以简化操作系统内核中很多部分的代码，是十分值得的。
  在本次实验中，需要亲自体验平常使用的**malloc**/**free**应该如何实现。在多处理器系统中，各个处理器上的代码会并发地申请或释放内存，这会给内存分配和释放带来额外的挑战——一方面，希望不同处理器可以并行、高效地申请内存，少量甚至不会出现同时申请而产生一个处理器等待另一个处理器的情况;另一方面，不希望**malloc**/**free**仅仅通过简单粗暴使用一把互斥锁来保护，从而降低了内存管理的效率


## 实验描述

> <u>实验要求1:实现多处理器安全的内存分配和回收</u>
>> 类似于**malloc**/**free**，在bare-metal上实现内存分配/回收的函数:
>> ```c
static void *kalloc(size_t size) {
	//内存分配
}

static void *kfree(void *ptr) {
	//内存释放
}
```
> 在AbstractMachine启动后，$[heap.start, heap.end]$都是可用的物理内存(堆区)，`kalloc`返回的内存必须位于这个区间中。具体来说这个实验中你需要实现一个数据结构，维护一个不相交区间的集合(堆区)
> $$H = \{[\mathcal{l}_{0},\mathcal{r}_{0}),[\mathcal{l}_{1},\mathcal{r}_{1}),....,[\mathcal{l}_{n},\mathcal{r}_{n})\}$$
> 初始时，堆区为空。假设当前堆区为$H$，$heap.start = L，heap.end = R$
> - `kalloc(s)分配s字节的内存$[\mathcal{l}, \mathcal{r})$满足
>     分配发生在堆区中$$(L \le \mathcal{l} < \mathcal{r} \le R)$$
>     分配的内存不与已分配内存重叠($$\forall[\mathcal{l}_{i}, \mathcal{r}_{i}) \in H. [\mathcal{l}, \mathcal{r}) \cap [\mathcal{l}_{i}, \mathcal{r}_{i}) = \emptyset $$)
>   得到新的堆区
>   $$ H^{'} = H \cup \{[\mathcal{l}, \mathcal{r})\}$$
>   并返回新分配区间的左端点$\mathcal{l}$
> - `kfree($\mathcal{l}$)删除一个已有区间$[\mathcal{l}, \mathcal{r}) \in H$，得到新的堆区
>    $$H^{'} = H \setminus \{[\mathcal{l}, \mathcal{r})\}$$
>   当$\mathcal{l}$不是$H$中任何一个区间左端点时，产生**undefined behavior**
>
> 除了上面的抽象描述，还有一些作为**计算机系统软件基础设施**的要求:
> - 对于大小为$s$的内存分配请求，返回的内存地址必须对齐到$2^{i}$，其中$i$是最小的满足$2^{i} \ge s$。例如，分配17字节内存返回的地址必须是32的整数倍
> - 在分配算法不能找到足够的内存继续分配时，返回`NULL(0)`
>   - 受分配算法的局限，可能系统中仍然有空闲的内存，但形成了碎片的内存，或者单纯是分配算法不能找到这些内存而导致失败，这是允许的。
> - 由于这些API仅仅在自制的操作系统内核中使用，可以直接拒绝超过16MB的内存分配
> - 不必初始化返回的内存，当然，对返回的内存赋上初始值是个不错的主意
> - 最重要的要求在于**允许多处理器并行地调用`kalloc`/`kfree`**:
>   - 不同的处理器可能同时执行`kalloc`分配大小不同的内存
>   - 不同的处理器可能同时执行`kfree`释放内存
>   - 在一个处理器分配的内存，可能在另一个处理器上释放
>   - 在`kalloc`/`kfree`实现正确的前提下，尽可能使不同处理器上的内存分配能够并行
>
> <u>实验要求2:实现AbstractMachine中缺失的函数</u>
>> 在L0中，已经提出了这个实验要求。从现在开始，正式建议实现klib里缺失的函数——没有`printf`、`sprintf`等函数，根本就是在使用汇编语言写操作系统


## 实验指南

### 代码组织与运行

  实验框架代码由三个目录组成:

  ```
.
+--framework	->	框架代码;	可以在本地修改
|	+--kernel.h
|	+--main.c
+--include	->	头文件;	可以自由修改/创建文件
|	+--common.h
+--Makefile
+--src		->	源文件; 可以自由修改/创建文件
    +--os.c
    +--pmm.c
```

  可以使用前面提到的技巧(即执行`make -nB  | sed "s/^/\n/g" | sed "s/ /\n\t/g"`，观察并了解整个系统镜像的生成过程:
  1. 首先，其编译相关的源文件,生成目标文件，样例如下所示
  ```bash
x86_64-linux-gnu-gcc
        -std=gnu11
        -O2
        -MMD
        -Wall
        -Werror
        -ggdb
        -Iinclude/
        -Iframework/
        -I/home/hawk/Desktop/nju/kernel/include
        -I/home/hawk/Desktop/nju/kernel/../abstract-machine/am/include/
        -I/home/hawk/Desktop/nju/kernel/../abstract-machine/klib/include/
        -D__ISA__=\"x86_64\"
        -D__ISA_X86_64__
        -D__ARCH__=x86_64-qemu
        -D__ARCH_X86_64_QEMU
        -D__PLATFORM__=qemu
        -D__PLATFORM_QEMU
        -DARCH_H=\"arch/x86_64-qemu.h\"
        -fno-asynchronous-unwind-tables
        -fno-builtin
        -fno-stack-protector
        -Wno-main
        -m64
        -fPIC
        -mno-sse
        -c
        -o
        /home/hawk/Desktop/nju/kernel/build/x86_64-qemu/framework/main.o
        /home/hawk/Desktop/nju/kernel/framework/main.c
```
  2. 链接生成ELF文件，命令如下
  ```bash
x86_64-linux-gnu-ld
        -melf_x86_64
        -N
        -Ttext-segment=0x00100000
        -o
        /home/hawk/Desktop/nju/kernel/build/kernel-x86_64-qemu.elf
        /home/hawk/Desktop/nju/kernel/build/x86_64-qemu/framework/main.o
        /home/hawk/Desktop/nju/kernel/build/x86_64-qemu/./src/pmm.o
        /home/hawk/Desktop/nju/kernel/build/x86_64-qemu/./src/os.o
        /home/hawk/Desktop/nju/kernel/../abstract-machine/am/build/am-x86_64-qemu.a
        /home/hawk/Desktop/nju/kernel/../abstract-machine/klib/build/klib-x86_64-qemu.a
```
  3. 最后，生成可以运行的磁盘镜像文件，其命令如下所示
  ```bash
(
        cat
        /home/hawk/Desktop/nju/kernel/../abstract-machine/am/src/x86/qemu/boot/bootblock.o;
        head
        -c
        1024
        /dev/zero;
        cat
        /home/hawk/Desktop/nju/kernel/build/kernel-x86_64-qemu.elf
        )
        >
        /home/hawk/Desktop/nju/kernel/build/kernel-x86_64-qemu
```

  如果想要运行的话，和之前L0的实验是类似的，使用make即可执行，指令如下所示
  ```bash
make run ARCH=x86_64-qemu
```

  如果要启动多个处理器，则传递`smp`环境变量即可，执行如下命令即可启动4各处理器
  ```bash
make run ARCH=x86_64-qemu smp = 4
```

### 框架代码导读

  框架代码很短，其从`main`函数首先执行os的初始化，然后启动多个处理器，每个处理器都跳转到`os->run`执行
  ```c
int main() {
  os->init();
  mpe_init(os->run);
  return 1;
}
```

  `os`是一个操作系统的**模块**，可以看成是使用C实现的面向对象的编程，可曾强代码的可读性。其主要借助于下面的宏，实现模块的声明和定义
  ```c
#define MODULE(mod) \
  typedef struct mod_##mod##_t mod_##mod##_t; \
  extern mod_##mod##_t *mod; \
  struct mod_##mod##_t

#define MODULE_DEF(mod) \
  extern mod_##mod##_t __##mod##_obj; \
  mod_##mod##_t *mod = &__##mod##_obj; \
  mod_##mod##_t __##mod##_obj
```

  上面`MODULE`用来声明一个模块，而使用`MODULE_DEF`来真正的定义这个模块。当然，这样子的视觉效果不是很好，可以将前面相关的编译命令中的**-c**参数更换为**-E**，其有如下形式的代码
  ```c
typedef struct mod_os_t mod_os_t; extern mod_os_t *os; struct mod_os_t {
  void (*init)();
  void (*run)();
};


extern mod_os_t __os_obj; mod_os_t *os = &__os_obj; mod_os_t __os_obj = {
  .init = os_init,
  .run = os_run,
};
```

  实际上想要读懂这份宏，需要弄明白二点:
  1. 宏是字面替换，`MODULE(mod)`中所有的**mod**都会被替换掉
  2. **##**是C语言用来拼接标识符的机制，`sys ## tem`，可以得到`system`


### 框架代码的运行

  在当前的操作系统内核中，目前只有两个函数
  - `os->init()`，其完成操作系统所有部分的初始化。`os_init()`运行在系统启动后的第一个处理器上，中断处于关闭状态;此时系统中的其他处理器尚未被启动
  - `os->run()`是所有处理器的入口，在初始化完成后，框架代码调用`mpe_init(os->run)`，启动所有处理器执行。原始框架代码中，`os->run`只是打印**Hello World**之后就开始死循环;你之后可以在`os->run`中添加各种测试代码


### 实现`kalloc`/`kfree`

  相关的实现主要在**pmm(physical memory management)**模块:
  ```c
MODULE(pmm) {
	void (*init)();
	void *(alloc)(size_t size);
	void (*free)(void *ptr);
}
```

  该模块共包含三个函数指针:
  - `pmm->init()`初始化`pmm`模块，其应该在多处理器启动前，即`os->init()`中调用。这里应该实现数据结构、锁的初始化等
  - `pmm->alloc()`，即对应实验要求中的`kalloc`
  - `pmm->free()`，即对应实验要求中的`kfree`


### 测试/调试代码

#### 构建测试框架

  AbstractMachine代码的调试是比较困难的——无论是native，亦或是在qemu模拟器中。因此，同构构建一个测试框架，对于定位bug是非常有用的
  下面以调用**thread.h**中API为例，构建一个测试代码框架
  首先创建一个**test**目录，用于存放和测试相关的代码，如下所示
  ```
test
  +——am.h			一个空的am.h
  +——common.h
  +——test.c
  +——threads.h			前面课程中给出的pthread包装API
```

  为了修改最少的代码，并且能够兼容已有的项目，可以在**pmm.c**文件中，增加一些条件编译，如下所示
  ```c
#ifndef TEST
// 框架代码中的 pmm_init (在 AbstractMachine 中运行)
static void pmm_init() {
  uintptr_t pmsize = ((uintptr_t)heap.end - (uintptr_t)heap.start);
  printf("Got %d MiB heap: [%p, %p)\n", pmsize >> 20, heap.start, heap.end);
}
#else
// 测试代码的 pmm_init ()
static void pmm_init() {
  char *ptr  = malloc(HEAP_SIZE);
  heap.start = ptr;
  heap.end   = ptr + HEAP_SIZE;
  printf("Got %d MiB heap: [%p, %p)\n", HEAP_SIZE >> 20, heap.start, heap.end);
}
#endif
```

  接着在对应的Makefile文件中，增加一个编译目标
  ```makefile
test: git
        @gcc $(shell find src/ -name "*.c")  \
             $(shell find test/ -name "*.c") \
             -Iframework -Itest -DTEST -lpthread \
             -o build/test
        @build/test
```

#### 设计测试用例

  为了确保代码在各种场合下，都可以正常的运行，需要尝试各种类型下的极端测试。此时，可以简单的利用前面构建的代码框架，批量地运行很多测试，如下所示
  ```c
int main(int argc, char *argv[]) {
  if (argc < 2) exit(1);
  switch(atoi(argv[1])) {
    case 0: do_test_0();
    case 1: do_test_1();
    ...
  }
}
```

  然后在Makefile里批量地进行运行，如下所示
  ```makefile
testall: test
        @build/test 0
        @build/test 1
        @build/test 2
        ...
```


#### 性能调优

  此时需要选取适当的**workload**进行调优，并且确定程序的性能瓶颈。理解程序性能的最好方法是使用正确的工具:**profiler**。作为本地进程运行的测试用例，其可以使用Linux系统自带的各种工具，快速的判断程序的性能瓶颈


## 实验环境

  类似的，切换到master分支，然后从github上拉取**L1**实验即可
  ```bash
git checkout master && git pull origin L1
```

## 实验实现

  下面是个人的思路及其实现，[实验实现](nju.tar.gz)

### 测试框架

  虽然按照实验指南的说明，对于多处理器的AbstractMachine来说，无论是在native亦或是QEMU模拟器中，由于AM APIs都和系统有紧密的耦合，因此调试起来并不是很方便。但实际上并非如此——在gdb中，无论是在QEMU模拟器中、亦或是native中，多处理器中的每一个处理器都相当于一个线程，因此使用gdb中调试多线程的方式来调试AbstractMachine代码即可
  不妨以QEMU模拟器为例，我们执行如下命令启动多处理器的AbstractMachine，其中**smp**参数指定多处理器数量
  ```bash
qemu-system-x86_64 -S -s -serial none -nographic -smp "2" build/kernel-x86_64-qemu
```

  然后在终端启动gdb，调试QEMU远程开启的远程gdb服务器，执行如下命令即可
  ```bash
gdb -ex "target remote localhost:1234"
```

  如果此时想要查看多处理器的处理器信息，并切换到指定的处理器上，则在gdb中执行如下调试多线程的命令进行查看
  ```bash
(gdb) info threads
(gdb) thread [threadId]
```

  可以看到，实际上调试多处理器的AbstractMachine并不是很困难。虽然如此，由于本次实验对于不同的workload的性能和准确性都有一定要求，因此构造一个测试框架，进行自动的编译、运行测试和清理是十分有帮助的。

  1. 添加条件编译

    为了最小程度的修改源代码，并且在任何时候都可以通过`make run`和`make test`命令，来编译、运行对应的正常样例和测试样例，我们通过添加条件编译来实现。除此之外，为了适应项目的需要，测试`kalloc`和`kfree`在不同workload下的正确性和性能，我们使用`switch`结构来实现该测试框架，这样子对于新的测试样例，只需要在`switch`中添加新的测试函数即可
    ```c
#include <common.h>

#ifndef TEST
int main() {
	os->init();
	mpe_init(os->run);
	return 1;
}

#else


/*
 * 判断测试样例是否正确
 */
static void check(int idx, bool condition, const char *message) {
	if(condition) { printf("\033[32m[%d] is correct\n%s\033[0m\n", idx, message); }
	else { printf("\033[31m[%d] is incorrect\n%s\033[0m\n", idx, message); }
	halt(0);
}


/*
 * 测试样例0
 * 测试框架是否正确
 */
static void test0() {
	if(!cpu_current()) { check(0, true, "test the tesing framework"); }
	else {
		while(true) {;}
	}
}


/*
 * 确保所有进程都执行完其函数
 */
int numberOfFinished = 0;
lock_t lock_numberOfFinished;


/*
 * 测试样例1
 * 测试互斥锁是否正确
 */
int test1_sum = 0, test1_count = 1000000;
lock_t lock_test1_sum;
static void test1() {
	if(!cpu_current()) {
		while(true) {
			while(!lock(&lock_numberOfFinished)) {;}
			if(numberOfFinished + 1 == cpu_count()) { check(1, test1_count * numberOfFinished == test1_sum, "test the lock"); }
			unlock(&lock_numberOfFinished);
		}
	}else {
		for(int i = 0; i < test1_count; ++i) {
			while(!lock(&lock_test1_sum)) {;}
			++test1_sum;
			unlock(&lock_test1_sum);
		}

		while(!lock(&lock_numberOfFinished)) {;}
		++numberOfFinished;
		unlock(&lock_numberOfFinished);

		while(1) {;}

	}
}




int main() {
	os->init();

	lock_init(&lock_numberOfFinished);
	/*
	 * 这里通过-DIDX=，传递宏参数
	 */
	switch(IDX) {
		case 0:
			mpe_init(test0);
			break;
		case 1:
			lock_init(&lock_test1_sum);
			mpe_init(test1);
		default:
			break;
	}

	return 0;
}
#endif
```

  2. 添加编译目标
  这里为了实现`make run`和`make test`自动编译和执行不同的内核，需要添加编译目标，并修改**kernel**目录下的相关Makefile
  ```makefile
NAME           := kernel
SRCS           := framework/main.c $(shell find -L ./src/ -name "*.c")
INC_PATH       := include/ framework/
TEST           := $(shell seq -f "test%g" 0 0)

export AM_HOME := $(PWD)/../abstract-machine
ifeq ($(ARCH),)
export ARCH    := x86_64-qemu
endif

include $(AM_HOME)/Makefile
include ../Makefile.lab
image: git


test: $(TEST)

test%: $(OBJS) am $(LIBS)
	@$(CC) -std=gnu11 $(CFLAGS) -DTEST -DIDX=$(subst test,,$@) -c -o build/$(ARCH)/framework/main.o framework/main.c
	@g++ -pie -o $(IMAGE) -Wl,--whole-archive $(LINKAGE) -Wl,-no-whole-archive -lSDL2 -ldl
	smp=$(smp) $(IMAGE)
```

  这里需要注意以下，实际上这里编译**test**目标，无法一次性完成测试——因为执行其中一个可执行文件后，其在退出时会执行`kill(0, sigkill)`，杀死了当前进程组中的所有进程，也包括当前的`make`命令。因此其执行一个测试样例后，就会自动退出
  [TODO]:
  这里需要一些特殊的方式来屏蔽掉该信号，从而使其可以一次性完成所有的测试样例

  3. 运行内核
  如果要运行正常模式下的内核，则只需要设置多处理器个数以及运行环境即可，执行如下命令在本机上模拟四核计算机
  ```bash
make ARCH=native smp=4 run
```

  如果要运行测试模式下的内核，则指定目标为**test**即可，即其命令如下所示
  ```bash
make ARCH=native smp=4 test
```


### 实现互斥锁

  AbstractMachine文档中给出了原子指令`int atomic_xchg(volatile int *addr, int newval)`，其会原子地交换内存地址中的数值。
  这里我们并不准备实现自旋锁(可以简单包装实现)，而仅仅实现一个互斥锁——其可以上锁和解锁，但如果上锁失败，其不会重新尝试。相关结构如下所示
  ```c
#include <common.h>


#define locked		(0)
#define unlocked	(1)



/*
 * 上锁
 * 如果上锁成功，则程序可以独占资源，直到主动释放锁
 * 如果上锁失败，则直接返回，不会重新尝试(即非自旋锁)
 */
bool lock(lock_t *lk) {
	return atomic_xchg(lk, locked) == unlocked;
}


/*
 * 释放锁
 * 即释放之前上的锁，释放独占资源
 */
void unlock(lock_t *lk) {
	atomic_xchg(lk, unlocked);
}


/*
 * 初始化锁
 * 即将锁的值更改为unlocked
 */
void lock_init(lock_t *lk) {
	unlock(lk);
}
```

  可以看到，这里实现了一个简易的非阻塞的互斥锁。如果想要实现自旋锁(阻塞式的互斥锁)，只需要在`lock`操作失败后重试即可


### 分配对象结构简述

  本质上，内存管理是按照一定规则从系统内存上申请内存对象;当释放的时候，再按照一定的规则缓存起来，等待下次申请内存对象时直接使用，而非直接返回给系统，从而提高内存管理的效率和性能。

  因此，我们需要根据内存申请的特点，构造对应的内存对象数据结构，从而提高内存管理的效率和安全性。根据前面的实验要求和实验指南:一方面，返回的内存地址必须对齐到$2^{i}$;另一方面，请求的内存大小有如下特征:
  1. 大量、频繁的小内存分配和释放;绝大部分不超过128字节;
  2. 较为频繁的，以物理页面大小为单位的分配/释放(4KiB)
  3. 非常罕见的大内存分配


  为了尽可能的高并发，在内存中构建与处理器等数量的内存管理结构，并以循环链表的形式进行管理——每个处理器在申请内存时，会循环遍历这些内存管理结构，找到一个未上锁的内存管理结构，并完成相关的内存申请。
  由于其内存地址需要对齐到$2^{i}$，则我们使用**伙伴算法**;而由于其频繁、大量的进行小内存分配和释放，因此我们使用**slab机制**缓存所有大小相同的内存对象。
  ![内存布局](内存布局.PNG)

### 申请大小对齐到$2^{i}$

  实际上部分CPU提供时间复杂度为$O(1)$的硬件解决方法，但是其没有可移植性。因此我们还是通过二分的软件方法进行实现。
  其思路就是通过位运算，其随着位运算的左移个数增加而值减少，是单调的。因此可以通过二分查找，以$O(logn)$的时间复杂度解决
  ```c
//计算ceil(log_{a}^{n})
#define BITPERCHAR 8
static inline int64_t log(int64_t a, int64_t n) {
	//因为a > 1，则直接取a = 2即可
	assert(a > 1 && n >= 0);

	//为了避免n恰好为2的幂指数，首先减1在计算
	--n;

	int64_t left = 0, right = sizeof(int64_t) / sizeof(char) * BITPERCHAR - 1;

	while(left <= right) {
		int middle = left + (right - left) / 2;
		if(n >> middle) { left = middle + 1; }
		else { right = middle - 1; }
	}

	return left;
}


/*
 * 将内存的请求大小对齐到2 ^ {i}
 */
#ifndef TEST
static
#endif
size_t request2size(size_t req) {
	return ((size_t)1) << log(2, req);
}
```



### 伙伴算法

  伙伴算法，或者**Buddy**算法，是一种能有效提高内存利用率，且降低内部碎片的内存管理算法。

#### 初始化伙伴算法
  由于伙伴算法涉及到对象的拆分和合并，其往往需要互斥的访问一些共享资源(比如位图等)。因此在本实验中，其属于实验指南中的"slow path"，用来分配大内存或者当用于分配中、小内存的**slab机制**耗尽资源时的内存分配
  由于伙伴算法中所有的内存对象都是连续分布的，且其大小都是$2^{i}$;因此只要内存地址最小的内存对象，其内存地址是对齐的，则后面所有的内存地址都是自动对齐的。
  分配的时候，由于内存对象位于双向链表的表头数组中，其每一个元素都是大小相同的内存对象组成的双向循环链表，则我们根据内存对象在表头数组中的下标，可以直观的知道该内存对象对应的大小信息;但是在释放的时候，由于内存对象中并没有存储内存的大小信息，则我们无法直接获取该内存的大小信息。这里，我们使用数组，将其从页序号(即虚拟地址左移12位)映射到该内存对象的大小对应的双向链表的表头数组下标，从而在释放内存对象时，仅仅根据其虚拟地址获取内存对象的大小信息
  最后，这里为了避免初始化时间过长，则默认一开始所有的内存对象的大小都是允许分配的最大的内存大小(实验指导中规定的是**16MB**)——这样前面映射数组初始化为对应的下标即可
  ```c
/*
 * 设置Buddy算法的相关参数
 */
#define B  * (1)
#define KB * (1024)
#define MB * (1024 KB)
#define LOG_PAGE_SIZE (12)
#define PAGE_SIZE (1 << LOG_PAGE_SIZE)
#define MAX_SIZE  (16 MB)



/*
 * 初始化Buddy结构
 * 一开始默认所有的内存对象都属于最大下所对应的内存对象
 * 初始化对应的映射结构、锁结构等
 */
typedef struct MALLOC_CHUNK {
	//当内存对象处于未使用、或被free时，通过 MALLOC_CHUNK来管理
	struct MALLOC_CHUNK *fd;
	struct MALLOC_CHUNK *bk;	//该字段仅在buddy的双向链表结构中使用，slab中不使用该字段
} Malloc_Chunk;

typedef struct BUDDY {
	Malloc_Chunk *ptr_list;		//即指向buddy的双向链表的表头数组
	unsigned char *ptr_page2idx;	//将虚拟地址对应的虚拟页根据其内存对象的大小，映射到所属的表头数组对应的下标中
	uintptr_t startAddress;		//即虚拟地址在ptr_page2idx数组的下标为:(address - startAddress) >> LOG_PAGE_SIZE
	lock_t lock_buddy;		//buddy结构体中的双向链表的表头数组的锁
	int buddy_size;			//即双向链表的表头数组的个数
} Buddy;


//buddy相关的宏操作
#define buddy_ptr_list_at(buddy, idx) (((Malloc_Chunk*)((buddy)->ptr_list)) + (idx))
#define buddy_get_chunk_use_flag(buddy, address) (((Buddy*)(buddy))->ptr_page2idx[(((uintptr_t)(address)) - ((Buddy*)(buddy))->startAddress) >> LOG_PAGE_SIZE] >> (sizeof(unsigned char) * 8 - 1))
#define buddy_set_chunk_used(buddy, address) (((Buddy*)(buddy))->ptr_page2idx[(((uintptr_t)(address)) - ((Buddy*)(buddy))->startAddress) >> LOG_PAGE_SIZE] |= (((uint64_t)1) << (sizeof(unsigned char) * 8 - 1)))
#define buddy_set_chunk_unused(buddy, address) (((Buddy*)(buddy))->ptr_page2idx[(((uintptr_t)(address)) - ((Buddy*)(buddy))->startAddress) >> LOG_PAGE_SIZE] &= ((((uint64_t)1) << (sizeof(unsigned char) * 8 - 1)) - 1))
#define buddy_get_idx(buddy, address) (((Buddy*)(buddy))->ptr_page2idx[(((uintptr_t)(address)) - ((Buddy*)(buddy))->startAddress) >> LOG_PAGE_SIZE] & ((((uint64_t)1) << (sizeof(unsigned char) * 8 - 1)) - 1))
#define buddy_set_idx(buddy, address, idx) (((Buddy*)(buddy))->ptr_page2idx[(((uintptr_t)(address)) - ((Buddy*)(buddy))->startAddress) >> LOG_PAGE_SIZE] = ((idx) | (((uint64_t)buddy_get_chunk_use_flag((buddy), (address))) << (sizeof(unsigned char) * 8 - 1))))


#ifndef TEST
static
#endif
Buddy *buddy = (Buddy*)NULL;


//将节点从双向循环链表中摘下来
static void list_remove(Malloc_Chunk *malloc_chunk) {
	//确保当前链表元素个数一个(因为始终会有一个表头)
	assert(malloc_chunk && malloc_chunk->fd != malloc_chunk);

	assert(malloc_chunk->fd->bk == malloc_chunk && malloc_chunk->bk->fd == malloc_chunk);

	Malloc_Chunk *fwd = malloc_chunk->fd, *bck = malloc_chunk->bk;

	fwd->bk = bck;
	bck->fd = fwd;
}
//将节点插入到bin和bin->fd之间
static void list_insert(Malloc_Chunk *bin, Malloc_Chunk *malloc_chunk) {

	//确认参数都有效
	assert(malloc_chunk && bin);

	//确认bin是有效的双向链表
	assert(bin->fd->bk == bin && bin->bk->fd == bin);

	Malloc_Chunk *bck = bin, *fwd = bin->fd;
	bck->fd = malloc_chunk;
	fwd->bk = malloc_chunk;
	malloc_chunk->fd = fwd;
	malloc_chunk->bk = bck;
}

//	初始化buddy相关的数据结构信息
static int64_t buddy_init(void) {

	//首先将heap.start和heap.end对齐到16MB，并且将heap.start偏移16MB，方便保留相关的数据
	uintptr_t heapStart = (((uintptr_t)heap.start) + 2 * MAX_SIZE - 1) & (~(MAX_SIZE - 1)), heapEnd = ((uintptr_t)heap.end) & (~(MAX_SIZE - 1));


	//即双链表的表头数组
	Malloc_Chunk *malloc_chunk = (Malloc_Chunk*)(heap.start + sizeof(Buddy));


	//其buddy_size即倍增的双链表的个数，同样也是双链表的表头数组的元素个数，即0、1、...、log_ceil(2, MAX_SIZE / PAGE_SIZE)
	int buddy_size = log_ceil(2, MAX_SIZE / PAGE_SIZE) + 1;


	//其次是ptr_page2idx，这里为了实现简单，直接将一个页的状态以一个unsigned char表示。因为双链表元素个数最多log_ceil(MAX_SIZE / PAGE_SIZE)，因此unsigned char完全足够表示(这里4bit即可)
	unsigned char *ptr_page2idx = (unsigned char *)(heap.start + sizeof(Buddy) + buddy_size * sizeof(Malloc_Chunk));


	//填充buddy全局变量
	buddy->ptr_list = malloc_chunk;
	buddy->ptr_page2idx = ptr_page2idx;
	buddy->startAddress = heapStart;
	buddy->buddy_size = buddy_size;
	lock_init(&(buddy->lock_buddy));


	//初始化双向链表
	for(int i = 0; i < buddy_size; ++i) {
		malloc_chunk[i].fd = malloc_chunk[i].bk = malloc_chunk + i;
	}


	//初始化内存对象，将内存以允许的最大内存大小进行切割
	uintptr_t chunk = heapStart;
	Malloc_Chunk *lastbin = buddy_ptr_list_at(buddy, buddy_size - 1);
	while(chunk < heapEnd) {

		//首先设置内存的映射关系
		buddy_set_idx(buddy, chunk, buddy_size - 1);
		buddy_set_chunk_unused(buddy, chunk);

		//接着将该内存对象插入到双向链表数组中
		list_insert(lastbin, (Malloc_Chunk*)chunk);

		chunk += MAX_SIZE;
	}



	return sizeof(Buddy) + buddy_size * sizeof(Malloc_Chunk) + sizeof(unsigned char) * (heapEnd - heapStart) / PAGE_SIZE;
}
```

#### 获取内存

  对于**Buddy**来说，要从**Buddy**中获取内存:
  首先要检查申请大小——其申请的大小至少是**PAGE_SIZE(4096B)**，且最大不超过**MAX_SIZE(16MB)**，并且应该是$2^{i}$对齐的。
  其次，获取锁结构，从而互斥的访问——这里需要自旋锁，所以应该稍微包装一下相关的锁结构，即在上锁失败后重试
  然后，其从对应的表头数组下标处获取一个内存对象并返回即可;如果当前表头数组下标处没有可用的内存对象，则二分表头数组中最近的更大的内存对象，然后返回即可;如果仍然没有符合条件的，则返回NULL即可
  最后需要说明一下，为了可以快速的区分内存对象是否已经被分配，可以在**Buddy**的映射数组中进行标记——如果已经分配，则将其序号的最高比特置为1即可。
  ```c
/*
 * 从Buddy伙伴中直接获取不小于PAGE_SIZE、不大于MAX_SIZE的内存对象即可，并且请求大小已经对齐
 */

#ifndef TEST
static
#endif
void *buddy_malloc(size_t size) {

	//确保请求大小合规
	assert(size >= PAGE_SIZE && size <= MAX_SIZE && !(size & (size - 1)));


	//获取自旋锁 
	while(!lock(&(buddy->lock_buddy))) {;}


	int idx = log_ceil(2, size >> LOG_PAGE_SIZE);

	//如果当前buddy中包含该大小的内存对象，则直接返回该对象即可
	Malloc_Chunk *bin = buddy_ptr_list_at(buddy, idx);
	if(bin->bk != bin) {
		void *victim = bin->bk;
		list_remove(victim);
		buddy_set_chunk_used(buddy, victim);

		unlock(&(buddy->lock_buddy));
		return victim;
	}else {
		//首先找到大于当前下标的可用的内存对象
		Malloc_Chunk *split = NULL;
		int splitIndex = idx + 1;
		for(; splitIndex < buddy->buddy_size; ++splitIndex) {
			bin = buddy_ptr_list_at(buddy, splitIndex);
			if(bin->bk != bin) {
				split = bin->bk;
				assert(!buddy_get_chunk_use_flag(buddy, split));
				list_remove(split);
				break;
			}
		}


		if(split) {
			//将split对应的内存对象分割到符合条件的大小即可
			while(splitIndex-- != idx) {
				Malloc_Chunk *remainder = (Malloc_Chunk*)(((uintptr_t)split) + (1 << splitIndex) * PAGE_SIZE);

				list_insert(buddy_ptr_list_at(buddy, splitIndex), remainder);
				buddy_set_chunk_unused(buddy, remainder);
				buddy_set_idx(buddy, remainder, splitIndex);
			}

			buddy_set_chunk_used(buddy, split);
			buddy_set_idx(buddy, split, idx);
			unlock(&(buddy->lock_buddy));
			return split;
		}
	}


	//最后没有符合条件的
	unlock(&(buddy->lock_buddy));
	return NULL;
}
```

#### 释放内存

  由于**Buddy**结构中的映射数组中保存有当前内存对象的大小，因此我们可以将该chunk插入**Buddy**的表头数组的对应下标处的双向循环链表中即可
  但是需要注意的是，在**Buddy**算法中，释放内存对象时需要进行合并——如果相邻的内存对象大小相同，其是已经被释放的内存对象，并且也是从同一个更大的内存对象中拆分的:则将临接内存对象从双向循环链表中摘下来，合并成原始的大内存对象，然后继续按照上面的步骤释放该合并过的内存对象即可
  这里由于其拆分时是二分进行拆分的，因此寻找另一个被拆分的块可以通过异或快速进行定位，即`Malloc_Chunk *adj = (Malloc_Chunk*)(((uintptr_t)(chunk)) ^ ((((uint64_t)1) << buddy_get_idx(buddy, chunk)) * PAGE_SIZE)`
  则根据上面的说明，**Buddy**算法的释放就是不断进行合并，直到内存对象没有可以合并的符合条件的相邻内存对象为止
  ```c
/*
 * 释放对应的内存对象
 * 并且合并符合条件的相邻的内存对象
 */
#ifndef TEST
static
#endif
void buddy_free(void *chunk) {
	//确保释放的内存对象是有效的
	assert(chunk);

	int idx = buddy_get_idx(buddy, chunk);

	//首先确保当前内存对象是被释放的，并且其大小是合法的
	assert(buddy_get_chunk_use_flag(buddy, chunk) && idx < buddy->buddy_size);

	Malloc_Chunk *malloc_chunk = (Malloc_Chunk*)chunk;

	//获取自旋锁 
	while(!lock(&(buddy->lock_buddy))) {;}


	for(; idx + 1 < buddy->buddy_size; ++idx) {
		//获取当前邻接的chunk，通过异或获取
		Malloc_Chunk *adj = (Malloc_Chunk*)(((uintptr_t)malloc_chunk) ^ ((((uint64_t)1) << idx) * PAGE_SIZE));

		//如果当前邻接的chunk符合条件——即是释放的，对应的大小也相等
		if(!buddy_get_chunk_use_flag(buddy, adj) && buddy_get_idx(buddy, adj) == idx) {
			list_remove(adj);

			//获取合并后的内存对象头
			malloc_chunk = malloc_chunk < adj ? malloc_chunk : adj;
		}else {
			//如果当前邻接的chunk不符合条件，则直接退出，将malloc_chunk完成设置并插入双向链表中
			break;
		}
	}


	//将malloc_chunk插入到对应的双向循环链表中
	buddy_set_idx(buddy, malloc_chunk, idx);
	buddy_set_chunk_unused(buddy, malloc_chunk);
	list_insert(buddy_ptr_list_at(buddy, idx), malloc_chunk);
	

	unlock(&(buddy->lock_buddy));
}
```
